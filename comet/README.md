
### Llama-2 training:

Based on the repo [EPFLLM](https://github.com/epfLLM/Megatron-LLM).


checkpoints:

- [llama-2-7b-atomic2020_name](https://huggingface.co/tqfang229/llama-2-7b-atomic2020_name): Baseline, finetuned on ATOMIC2020.
- [llama-2-7b-p_2i_chatgpt](https://huggingface.co/tqfang229/llama-2-7b-p_2i_chatgpt): Fine-tuned on ChatGPT-verbalized 2i queries + ATOMIC 1p queries.
- [llama-2-7b-p_2i](https://huggingface.co/tqfang229/llama-2-7b-p_2i): Fine-tuned on rube-based verbalized 2i queries + ATOMIC 1p queries.

### Llama-2 evaluation:

`COMET-M` folder and `ParaCOMET` folder.


